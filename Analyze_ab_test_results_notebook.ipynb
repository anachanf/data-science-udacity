{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze A/B Test Results\n",
    "\n",
    "\n",
    "## Table of Contents\n",
    "- [Introduction](#intro)\n",
    "- [Part I - Probability](#probability)\n",
    "- [Part II - A/B Test](#ab_test)\n",
    "- [Part III - Regression](#regression)\n",
    "\n",
    "\n",
    "<a id='intro'></a>\n",
    "### Introduction\n",
    "\n",
    "A/B tests are very commonly performed by data analysts and data scientists.  It is important that you get some practice working with the difficulties of these \n",
    "\n",
    "For this project, you will be working to understand the results of an A/B test run by an e-commerce website.  Your goal is to work through this notebook to help the company understand if they should implement the new page, keep the old page, or perhaps run the experiment longer to make their decision.\n",
    "\n",
    "<a id='probability'></a>\n",
    "#### Part I - Probability\n",
    "\n",
    "To get started, let's import our libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#We are setting the seed to assure you get the same answers on quizzes as we set up\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`1.` Now, read in the `ab_data.csv` data. Store it in `df`.\n",
    "\n",
    "a. Read in the dataset and take a look at the top few rows here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   timestamp      group landing_page  converted\n",
       "0   851104  2017-01-21 22:11:48.556739    control     old_page          0\n",
       "1   804228  2017-01-12 08:01:45.159739    control     old_page          0\n",
       "2   661590  2017-01-11 16:55:06.154213  treatment     new_page          0\n",
       "3   853541  2017-01-08 18:28:03.143765  treatment     new_page          0\n",
       "4   864975  2017-01-21 01:52:26.210827    control     old_page          1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the dataset\n",
    "df = pd.read_csv('ab_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Use the cell below to find the number of rows in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "294478"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the number of rows in the dataset\n",
    "num_rows = df.shape[0]\n",
    "num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. The number of unique users in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290584"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the number of unique users in the dataset\n",
    "num_unique_users = df['user_id'].nunique()\n",
    "num_unique_users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "d. The proportion of users converted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35173, 0.12104245244060237)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the number of converted users\n",
    "num_converted_users = df.query('converted == 1').user_id.nunique()\n",
    "\n",
    "# calculate the proportion of converted users\n",
    "prop_converted_users = num_converted_users/num_unique_users\n",
    "num_converted_users, prop_converted_users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "e. The number of times the `new_page` and `treatment` don't match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3893"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the number of 'treatment' rows that are not 'new_page'\n",
    "treat_df = df.query('group == \"treatment\"')\n",
    "treat_not_new = treat_df.query('landing_page != \"new_page\"').shape[0]\n",
    "\n",
    "# calculate the number of 'new_page' rows that are not 'treatment'\n",
    "land_new_df = df.query('landing_page == \"new_page\"')\n",
    "new_not_treat = land_new_df.query('group != \"treatment\"').shape[0]\n",
    "\n",
    "# calculate the total number of rows that do not match 'new_page' and 'treatment'\n",
    "num_no_match_new_treatment = treat_not_new + new_not_treat\n",
    "num_no_match_new_treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['control', 'treatment'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check which unique values are there in 'group' column\n",
    "df['group'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['old_page', 'new_page'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check which unique values are there in 'landing_page' column\n",
    "df['landing_page'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f. Do any of the rows have missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 294478 entries, 0 to 294477\n",
      "Data columns (total 5 columns):\n",
      "user_id         294478 non-null int64\n",
      "timestamp       294478 non-null object\n",
      "group           294478 non-null object\n",
      "landing_page    294478 non-null object\n",
      "converted       294478 non-null int64\n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 11.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# get summary information concerning the dataframe\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this dataset, there are no rows with missing data. All columns have non-null values for all rows.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` For the rows where **treatment** does not match with **new_page** or **control** does not match with **old_page**, we cannot be sure if this row truly received the new or old page. \n",
    "\n",
    "a. Now use the answer to the quiz to create a new dataset that meets the specifications from the quiz.  Store your new dataframe in **df2**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290585"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a new dataset df2 with only the rows where 'treatment' matches 'new_page' and\n",
    "# 'control' matches 'old_page'\n",
    "df2 = df.query('(group == \"treatment\" and landing_page == \"new_page\") or (group == \"control\" and landing_page == \"old_page\")')\n",
    "df2.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Double Check all of the correct rows were removed - this should be 0\n",
    "df2[((df2['group'] == 'treatment') == (df2['landing_page'] == 'new_page')) == False].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3.` Use **df2** and the cells below to answer questions for **Quiz3** in the classroom."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. How many unique **user_id**s are in **df2**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290584"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the number of unique users\n",
    "df2['user_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "b. There is one **user_id** repeated in **df2**.  What is it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the number of duplicated user_ids\n",
    "df2['user_id'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2893    773192\n",
       "Name: user_id, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the user_id of the duplicated user\n",
    "df2[df2['user_id'].duplicated()]['user_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The duplicated user has the user_id 773192.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. What is the row information for the repeat **user_id**? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1899</th>\n",
       "      <td>773192</td>\n",
       "      <td>2017-01-09 05:37:58.781806</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2893</th>\n",
       "      <td>773192</td>\n",
       "      <td>2017-01-14 02:55:59.590927</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id                   timestamp      group landing_page  converted\n",
       "1899   773192  2017-01-09 05:37:58.781806  treatment     new_page          0\n",
       "2893   773192  2017-01-14 02:55:59.590927  treatment     new_page          0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the row information for the duplicated user_id\n",
    "df2.query('user_id == 773192')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. Remove **one** of the rows with a duplicate **user_id**, but keep your dataframe as **df2**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# remove one of the rows with the duplicated user_id from df2\n",
    "df2.drop_duplicates(subset=['user_id'], keep='first',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if the duplicated user_id was removed\n",
    "df2['user_id'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`4.` Use **df2** in the cells below to answer the quiz questions related to **Quiz 4** in the classroom.\n",
    "\n",
    "a. What is the probability of an individual converting regardless of the page they receive?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11959708724499628"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the probability of an individual converting regardless of the landing_page\n",
    "df2['converted'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The probability of an individual converting regardless of the landing_page is 11.96%.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Given that an individual was in the `control` group, what is the probability they converted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1203863045004612"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the probability of an individual converting, given it is in control group\n",
    "(df2.query('group == \"control\"')['converted'] == 1).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The probability of an individual converting, given it is in the control group, is 12.04%.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Given that an individual was in the `treatment` group, what is the probability they converted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11880806551510564"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the probability of an individual converting, given it is in treatment group\n",
    "(df2.query('group == \"treatment\"')['converted'] == 1).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The probability of an individual converting, given it is in the treatment group, is 11.88%.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. What is the probability that an individual received the new page?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5000619442226688"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the probability of an individual to receive the new_page\n",
    "df2[df2['landing_page'] == 'new_page'].shape[0]/df2.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The probability of an individual to receive the new_page is 50%.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e. Consider your results from parts (a) through (d) above, and explain below whether you think there is sufficient evidence to conclude that the new treatment page leads to more conversions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's analyse the above values:** <br>\n",
    "**1. The probability that an individual receives the new page is 50%, which means that half of the individuals receive the new page and the other half receive the old page.** <br>\n",
    "**2. The probabilities of converting are:**\n",
    "- Probability of an individual regardless of the group: 11.96%\n",
    "- Probability of an individual from control group: 12.04%\n",
    "- Probability of an individual from treatment group: 11.88%\n",
    "\n",
    "**These 3 values are aproximately equivalent (12%), which means that there is no change in the conversions in the new page (treatment group) when compared with the old page (control group).** <br><br>\n",
    "**Considering the above values, we can conclude that there is no sufficient evidence that the new treatment page leads to more conversions.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ab_test'></a>\n",
    "### Part II - A/B Test\n",
    "\n",
    "Notice that because of the time stamp associated with each event, you could technically run a hypothesis test continuously as each observation was observed.  \n",
    "\n",
    "However, then the hard question is do you stop as soon as one page is considered significantly better than another or does it need to happen consistently for a certain amount of time?  How long do you run to render a decision that neither page is better than another?  \n",
    "\n",
    "These questions are the difficult parts associated with A/B tests in general.  \n",
    "\n",
    "\n",
    "`1.` For now, consider you need to make the decision just based on all the data provided.  If you want to assume that the old page is better unless the new page proves to be definitely better at a Type I error rate of 5%, what should your null and alternative hypotheses be?  You can state your hypothesis in terms of words or in terms of **$p_{old}$** and **$p_{new}$**, which are the converted rates for the old and new pages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The null and alternative hypotheses are:** <br>\n",
    "**H<sub>0</sub>: p<sub>new</sub>  $\\leqslant$ p<sub>old</sub> or p<sub>new</sub> - p<sub>old</sub> $\\leqslant$ 0**<br>\n",
    "**H<sub>1</sub>: p<sub>new</sub> $\\gt$  p<sub>old</sub> or p<sub>new</sub> - p<sub>old</sub> $\\gt$ 0**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` Assume under the null hypothesis, $p_{new}$ and $p_{old}$ both have \"true\" success rates equal to the **converted** success rate regardless of page - that is $p_{new}$ and $p_{old}$ are equal. Furthermore, assume they are equal to the **converted** rate in **ab_data.csv** regardless of the page. <br><br>\n",
    "\n",
    "Use a sample size for each page equal to the ones in **ab_data.csv**.  <br><br>\n",
    "\n",
    "Perform the sampling distribution for the difference in **converted** between the two pages over 10,000 iterations of calculating an estimate from the null.  <br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. What is the **conversion rate** for $p_{new}$ under the null? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11959708724499628"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the conversion rate for the new_page, assuming that \n",
    "# it is equal to the conversion rate in 'ab_data.csv' regardless \n",
    "# of the landing page\n",
    "p_newpage = df2['converted'].mean()\n",
    "p_newpage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. What is the **conversion rate** for $p_{old}$ under the null? <br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11959708724499628"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the conversion rate for the old_page, assuming that \n",
    "# it is equal to the conversion rate in 'ab_data.csv' regardless\n",
    "# of the landing page\n",
    "p_oldpage = df2['converted'].mean()\n",
    "p_oldpage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. What is $n_{new}$, the number of individuals in the treatment group?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145310"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the number of users in the treatment group \n",
    "# (landing_page: new_page)\n",
    "n_new = df2[df2['landing_page']=='new_page'].shape[0]\n",
    "n_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. What is $n_{old}$, the number of individuals in the control group?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145274"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the number of users in the control group \n",
    "# (landing_page: old_page)\n",
    "n_old = df2[df2['landing_page']=='old_page'].shape[0]\n",
    "n_old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e. Simulate $n_{new}$ transactions with a conversion rate of $p_{new}$ under the null.  Store these $n_{new}$ 1's and 0's in **new_page_converted**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 0])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simulate n_new transactions with a conversion rate of p_newpage \n",
    "# under the null\n",
    "new_page_converted = np.random.choice([0,1], n_new, p=(p_newpage, 1-p_newpage))\n",
    "new_page_converted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f. Simulate $n_{old}$ transactions with a conversion rate of $p_{old}$ under the null.  Store these $n_{old}$ 1's and 0's in **old_page_converted**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simulate n_old transactions with a conversion rate of p_oldpage \n",
    "# under the null\n",
    "old_page_converted = np.random.choice([0,1], n_old, p=(p_oldpage, 1-p_oldpage))\n",
    "old_page_converted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g. Find $p_{new}$ - $p_{old}$ for your simulated values from part (e) and (f)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0024865274506462587"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the difference between the probabilities of the new and old \n",
    "# pages of the simulated values\n",
    "new_page_converted.mean() - old_page_converted.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h. Create 10,000 $p_{new}$ - $p_{old}$ values using the same simulation process you used in parts (a) through (g) above. Store all 10,000 values in a NumPy array called **p_diffs**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate 10000 conversion rates differences\n",
    "# using sampling distribution with bootstrapping\n",
    "p_diffs = []\n",
    "\n",
    "for _ in range(10000):\n",
    "    boot_samp = df2.sample(df2.shape[0], replace=True)\n",
    "    \n",
    "    # get a separate dataset for each group: control and treatment\n",
    "    df_old = boot_samp.query('group == \"control\"')\n",
    "    df_new = boot_samp.query('group == \"treatment\"')\n",
    "    \n",
    "    # probabilities of conversion of each group\n",
    "    p_old = df_old['converted'].mean()\n",
    "    p_new = df_new['converted'].mean()\n",
    "    \n",
    "    # use as sample size the number of converted users in each group (1's)\n",
    "    n_old = df_old['converted'].shape[0]\n",
    "    n_new = df_new['converted'].shape[0]\n",
    "    \n",
    "    # simulate the values\n",
    "    old_conv = np.random.choice([0,1], n_old, p=(p_old, 1-p_old))\n",
    "    new_conv = np.random.choice([0,1], n_new, p=(p_new, 1-p_new))\n",
    "    \n",
    "    # store the conversion rates differences in p_diffs\n",
    "    p_diffs.append(new_conv.mean() - old_conv.mean())\n",
    "    \n",
    "# convert to a numpy array\n",
    "p_diffs = np.array(p_diffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i. Plot a histogram of the **p_diffs**.  Does this plot look like what you expected?  Use the matching problem in the classroom to assure you fully understand what was computed here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f25ab954668>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the histogram\n",
    "plt.hist(p_diffs);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The plot of the histogram is as expected: the histogram is symmetric and it is shaped as a bell curve which means that the data has a normal distribution.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f25aaeb48d0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# using this sampling distribution, simulate from the null by\n",
    "# creating a random normal distribution centered at 0 with the\n",
    "# same spread and size\n",
    "null_vals = np.random.normal(0, p_diffs.std(), p_diffs.size)\n",
    "\n",
    "# calculate the observed conversion rates for each page (new and old)\n",
    "n_converted_new = df2.query('landing_page == \"new_page\" and converted == 1').shape[0]\n",
    "n_converted_old = df2.query('landing_page == \"old_page\" and converted == 1').shape[0]\n",
    "rate_new = n_converted_new/n_new\n",
    "rate_old = n_converted_old/n_old\n",
    "\n",
    "# calculate the observed difference in the conversion rates\n",
    "obs_diff = rate_new - rate_old\n",
    "\n",
    "# plot the histogram and the line of the observed difference in the conversion rates\n",
    "plt.hist(null_vals);\n",
    "plt.axvline(x=obs_diff, color='red');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "j. What proportion of the **p_diffs** are greater than the actual difference observed in **ab_data.csv**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84609999999999996"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the proportion of the p_diffs that are greater than the observed difference\n",
    "# (P-value)\n",
    "p_value = (null_vals > obs_diff).mean()\n",
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k. Please explain using the vocabulary you've learned in this course what you just computed in part **j.**  What is this value called in scientific studies?  What does this value mean in terms of whether or not there is a difference between the new and old pages?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The proportion of the p_diffs that are greater than the actual difference is called the P-value. It is the probability of observing our statistic, or one more extreme in favor of the alternative, if the null is true.**<br>\n",
    "**The P-value is 0.8461 and the Type I error rate ($\\alpha$) is 0.05   (5%).**<br><br>\n",
    "**Based on the data, we fail to reject the null hypothesis because P-value $\\gt$ $\\alpha$.**<br>\n",
    "**Which means that the difference between the conversion rates of the new and the old pages is less or equal to zero (H<sub>0</sub>). In other words, with a type I error of 0.05, the new page doesn't lead to more conversions than the old page and there is no difference between the conversion rates of the new and the old pages.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "l. We could also use a built-in to achieve similar results.  Though using the built-in might be easier to code, the above portions are a walkthrough of the ideas that are critical to correctly thinking about statistical significance. Fill in the below to calculate the number of conversions for each page, as well as the number of individuals who received each page. Let `n_old` and `n_new` refer the the number of rows associated with the old page and new pages, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(17489, 17264, 145274, 145310)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# get the number of conversions for each page\n",
    "convert_old = df2.query('landing_page == \"old_page\" and converted == 1').shape[0]\n",
    "convert_new = df2.query('landing_page == \"new_page\" and converted == 1').shape[0]\n",
    "\n",
    "# get the total number of individuals who received each page\n",
    "n_old = df2.query('landing_page == \"old_page\"').shape[0]\n",
    "n_new = df2.query('landing_page == \"new_page\"').shape[0]\n",
    "\n",
    "convert_old, convert_new, n_old, n_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "m. Now use `stats.proportions_ztest` to compute your test statistic and p-value.  [Here](https://docs.w3cub.com/statsmodels/generated/statsmodels.stats.proportion.proportions_ztest/) is a helpful link on using the built in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.3109241984234394, 0.90505831275902449)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute the test statistic and P-value\n",
    "z_score, p_value = sm.stats.proportions_ztest(np.array([convert_new, convert_old]), np.array([n_new, n_old]), alternative='larger')\n",
    "z_score, p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.094941687240975514"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.stats as st\n",
    "\n",
    "# the cumulative distribution function indicates if z_score is significant\n",
    "st.norm.cdf(z_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.959963984540054"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the critical value with a confidence interval of 95%\n",
    "# using percent point function\n",
    "st.norm.ppf(1-(0.05/2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n. What do the z-score and p-value you computed in the previous question mean for the conversion rates of the old and new pages?  Do they agree with the findings in parts **j.** and **k.**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We fail to reject the null hypothesis because we have a P-value of 0.9051, greater than Type I error rate (0.05), and the z-score (1.3109) is bellow the critical value (1.95996).**<br>\n",
    "**Therefore, the difference between the conversion rates of the new and the old pages is lower or equal to zero (null hypothesis). In other words, there is no difference between conversion rates of the new and old pages, which is the same conclusion we reached in the parts j and k.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='regression'></a>\n",
    "### Part III - A regression approach\n",
    "\n",
    "`1.` In this final part, you will see that the result you achieved in the A/B test in Part II above can also be achieved by performing regression.<br><br> \n",
    "\n",
    "a. Since each row is either a conversion or no conversion, what type of regression should you be performing in this case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We should perform the Logistic Regression because it predicts a categorical response and it is used to predict one of two possible outcomes, like in this case: conversion or no conversion.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. The goal is to use **statsmodels** to fit the regression model you specified in part **a.** to see if there is a significant difference in conversion based on which page a customer receives. However, you first need to create in df2 a column for the intercept, and create a dummy variable column for which page each user received.  Add an **intercept** column, as well as an **ab_page** column, which is 1 when an individual receives the **treatment** and 0 if **control**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:3140: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "      <th>new_page</th>\n",
       "      <th>ab_page</th>\n",
       "      <th>intercept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   timestamp      group landing_page  converted  \\\n",
       "0   851104  2017-01-21 22:11:48.556739    control     old_page          0   \n",
       "1   804228  2017-01-12 08:01:45.159739    control     old_page          0   \n",
       "2   661590  2017-01-11 16:55:06.154213  treatment     new_page          0   \n",
       "3   853541  2017-01-08 18:28:03.143765  treatment     new_page          0   \n",
       "4   864975  2017-01-21 01:52:26.210827    control     old_page          1   \n",
       "\n",
       "   new_page  ab_page  intercept  \n",
       "0         0        0          1  \n",
       "1         0        0          1  \n",
       "2         1        1          1  \n",
       "3         1        1          1  \n",
       "4         0        0          1  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the dummy variable for the landing page (categorical variable)\n",
    "df2[['new_page', 'old_page']] = pd.get_dummies(df2['landing_page'])\n",
    "# drop old_page column\n",
    "df2 = df2.drop('old_page', axis=1)\n",
    "\n",
    "# create an ab_page column (1 if treatment, 0 if control)\n",
    "df2['ab_page'] = pd.get_dummies(df2['group'])['treatment']\n",
    "\n",
    "# create the intercept column in df2\n",
    "df2['intercept'] = 1\n",
    "\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Use **statsmodels** to instantiate your regression model on the two columns you created in part b., then fit the model using the two columns you created in part **b.** to predict whether or not an individual converts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366118\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "# create the logistic regression model\n",
    "logit_mod = sm.Logit(df2['converted'], df2[['intercept', 'ab_page']])\n",
    "\n",
    "# fit the model\n",
    "results = logit_mod.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. Provide the summary of your model below, and use it as necessary to answer the following questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>       <td>No. Iterations:</td>    <td>6.0000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>     <td>converted</td>    <td>Pseudo R-squared:</td>    <td>0.000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2020-03-24 20:37</td>       <td>AIC:</td>        <td>212780.3502</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>       <td>290584</td>            <td>BIC:</td>        <td>212801.5095</td>\n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>              <td>1</td>         <td>Log-Likelihood:</td>  <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>         <td>290582</td>          <td>LL-Null:</td>      <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>         <td>1.0000</td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>       <th>Coef.</th>  <th>Std.Err.</th>     <th>z</th>      <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>-1.9888</td>  <td>0.0081</td>  <td>-246.6690</td> <td>0.0000</td> <td>-2.0046</td> <td>-1.9730</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ab_page</th>   <td>-0.0150</td>  <td>0.0114</td>   <td>-1.3109</td>  <td>0.1899</td> <td>-0.0374</td> <td>0.0074</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                          Results: Logit\n",
       "==================================================================\n",
       "Model:              Logit            No. Iterations:   6.0000     \n",
       "Dependent Variable: converted        Pseudo R-squared: 0.000      \n",
       "Date:               2020-03-24 20:37 AIC:              212780.3502\n",
       "No. Observations:   290584           BIC:              212801.5095\n",
       "Df Model:           1                Log-Likelihood:   -1.0639e+05\n",
       "Df Residuals:       290582           LL-Null:          -1.0639e+05\n",
       "Converged:          1.0000           Scale:            1.0000     \n",
       "-------------------------------------------------------------------\n",
       "              Coef.   Std.Err.      z      P>|z|    [0.025   0.975]\n",
       "-------------------------------------------------------------------\n",
       "intercept    -1.9888    0.0081  -246.6690  0.0000  -2.0046  -1.9730\n",
       "ab_page      -0.0150    0.0114    -1.3109  0.1899  -0.0374   0.0074\n",
       "==================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the summary results of the model\n",
    "# note: using the 'summary' function, there was an internal error: the module \n",
    "# 'scipy.stats' has no attribute 'chisqprob'.\n",
    "results.summary2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e. What is the p-value associated with **ab_page**? Why does it differ from the value you found in **Part II**?<br><br>  **Hint**: What are the null and alternative hypotheses associated with your regression model, and how do they compare to the null and alternative hypotheses in **Part II**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The P-value associated with ab_page is 0.1899. In part II (A-B Test), the P-value was 0.8460. These values are different because in the case of Sampling Distribution (part II), the P-value refers to the probability of observing our statistic, or one more extreme in favor of the alternative, if the null is true, and in the case of the logistic regression (part III), the P-value associated with ab_page indicates if it is statistically significant in predicting the response variable (converted: 0 or 1).**<br><br>\n",
    "**The null and alternative hypothesis associated with the regression model are:**<br>\n",
    "**H<sub>0</sub>: no difference between conversion rates of treatment and control groups**<br>\n",
    "**H<sub>1</sub>: treatment and control groups conversion rates are different**<br><br>\n",
    "**The null and alternative hypothesis in part II are:**<br>\n",
    "**H<sub>0</sub>: new page conversion rate is lower or equal to the old page conversion rate**<br>\n",
    "**H<sub>1</sub>: new page conversion rate is greater than the old page conversion rate**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f. Now, you are considering other things that might influence whether or not an individual converts.  Discuss why it is a good idea to consider other factors to add into your regression model.  Are there any disadvantages to adding additional terms into your regression model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**It is a good idea to add other factors into our regression model in order to get a more complete analysis and understand other variables that might influence the conversion rate. Another variable that we could add to this regression model is timestamp. It would be usefull to analyse how it influences the conversion rate and we could extract different informations from the timestamp, for example: the time period of the day, if it is a weekday or weekend and the month of the year.**<br>\n",
    "**The disadvantage of adding additional terms into the regression model is the increase of complexity of the results interpretation.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g. Now along with testing if the conversion rate changes for different pages, also add an effect based on which country a user lives in. You will need to read in the **countries.csv** dataset and merge together your datasets on the appropriate rows. \n",
    "\n",
    "Does it appear that country had an impact on conversion?  Don't forget to create dummy variables for these country columns - **Hint: You will need two columns for the three dummy variables.** Provide the statistical output as well as a written response to answer this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>834778</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>928468</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>822059</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>711597</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>710616</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id country\n",
       "0   834778      UK\n",
       "1   928468      US\n",
       "2   822059      UK\n",
       "3   711597      UK\n",
       "4   710616      UK"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read country data from 'countries.csv' file\n",
    "country_df = pd.read_csv('countries.csv')\n",
    "country_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "      <th>new_page</th>\n",
       "      <th>ab_page</th>\n",
       "      <th>intercept</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   timestamp      group landing_page  converted  \\\n",
       "0   851104  2017-01-21 22:11:48.556739    control     old_page          0   \n",
       "1   804228  2017-01-12 08:01:45.159739    control     old_page          0   \n",
       "2   661590  2017-01-11 16:55:06.154213  treatment     new_page          0   \n",
       "3   853541  2017-01-08 18:28:03.143765  treatment     new_page          0   \n",
       "4   864975  2017-01-21 01:52:26.210827    control     old_page          1   \n",
       "\n",
       "   new_page  ab_page  intercept country  \n",
       "0         0        0          1      US  \n",
       "1         0        0          1      US  \n",
       "2         1        1          1      US  \n",
       "3         1        1          1      US  \n",
       "4         0        0          1      US  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge df2 and country_df datasets\n",
    "new_df = df2.merge(country_df, on='user_id', how='left')\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['US', 'CA', 'UK'], dtype=object)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check which countries are there in the dataset\n",
    "new_df['country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "      <th>new_page</th>\n",
       "      <th>ab_page</th>\n",
       "      <th>intercept</th>\n",
       "      <th>country</th>\n",
       "      <th>UK</th>\n",
       "      <th>US</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   timestamp      group landing_page  converted  \\\n",
       "0   851104  2017-01-21 22:11:48.556739    control     old_page          0   \n",
       "1   804228  2017-01-12 08:01:45.159739    control     old_page          0   \n",
       "2   661590  2017-01-11 16:55:06.154213  treatment     new_page          0   \n",
       "3   853541  2017-01-08 18:28:03.143765  treatment     new_page          0   \n",
       "4   864975  2017-01-21 01:52:26.210827    control     old_page          1   \n",
       "\n",
       "   new_page  ab_page  intercept country  UK  US  \n",
       "0         0        0          1      US   0   1  \n",
       "1         0        0          1      US   0   1  \n",
       "2         1        1          1      US   0   1  \n",
       "3         1        1          1      US   0   1  \n",
       "4         0        0          1      US   0   1  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the dummy variables\n",
    "new_df[['CA', 'UK', 'US']] = pd.get_dummies(new_df['country'])\n",
    "\n",
    "# drop CA column\n",
    "new_df = new_df.drop('CA', axis=1)\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366113\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>       <td>No. Iterations:</td>    <td>6.0000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>     <td>converted</td>    <td>Pseudo R-squared:</td>    <td>0.000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2020-03-24 20:39</td>       <td>AIC:</td>        <td>212781.1253</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>       <td>290584</td>            <td>BIC:</td>        <td>212823.4439</td>\n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>              <td>3</td>         <td>Log-Likelihood:</td>  <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>         <td>290580</td>          <td>LL-Null:</td>      <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>         <td>1.0000</td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>       <th>Coef.</th>  <th>Std.Err.</th>     <th>z</th>     <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>-2.0300</td>  <td>0.0266</td>  <td>-76.2488</td> <td>0.0000</td> <td>-2.0822</td> <td>-1.9778</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ab_page</th>   <td>-0.0149</td>  <td>0.0114</td>   <td>-1.3069</td> <td>0.1912</td> <td>-0.0374</td> <td>0.0075</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>UK</th>        <td>0.0506</td>   <td>0.0284</td>   <td>1.7835</td>  <td>0.0745</td> <td>-0.0050</td> <td>0.1063</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>US</th>        <td>0.0408</td>   <td>0.0269</td>   <td>1.5161</td>  <td>0.1295</td> <td>-0.0119</td> <td>0.0934</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                          Results: Logit\n",
       "==================================================================\n",
       "Model:              Logit            No. Iterations:   6.0000     \n",
       "Dependent Variable: converted        Pseudo R-squared: 0.000      \n",
       "Date:               2020-03-24 20:39 AIC:              212781.1253\n",
       "No. Observations:   290584           BIC:              212823.4439\n",
       "Df Model:           3                Log-Likelihood:   -1.0639e+05\n",
       "Df Residuals:       290580           LL-Null:          -1.0639e+05\n",
       "Converged:          1.0000           Scale:            1.0000     \n",
       "-------------------------------------------------------------------\n",
       "               Coef.   Std.Err.     z      P>|z|    [0.025   0.975]\n",
       "-------------------------------------------------------------------\n",
       "intercept     -2.0300    0.0266  -76.2488  0.0000  -2.0822  -1.9778\n",
       "ab_page       -0.0149    0.0114   -1.3069  0.1912  -0.0374   0.0075\n",
       "UK             0.0506    0.0284    1.7835  0.0745  -0.0050   0.1063\n",
       "US             0.0408    0.0269    1.5161  0.1295  -0.0119   0.0934\n",
       "==================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the logistic regression model\n",
    "logit_mod2 = sm.Logit(new_df['converted'], new_df[['intercept', 'ab_page', 'UK', 'US']])\n",
    "\n",
    "# fit the model\n",
    "results2 = logit_mod2.fit()\n",
    "\n",
    "# get results summary\n",
    "# note: using the 'summary' function, there was an internal error: the module\n",
    "# 'scipy.stats' has no attribute 'chisqprob'\n",
    "results2.summary2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From this summary, we can interpret as follows:**<br>\n",
    "**1. The P-values of the variables (except the intercept) have not low values (greater than 0.05) and that suggests that there are no variables statistically significant for the conversion rate.**<br>\n",
    "**2. A change in the variable ab_page decreases the odds of the conversion by 0.015, holding all other variables constant.**<br>\n",
    "**3. A change in UK users increases the odds of the conversion by 0.05, holding all other variables constant.**<br>\n",
    "**4. A change in US users increases the odds of conversion by 0.04, holding all other variables constant.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intercept    0.131332\n",
       "ab_page      0.985168\n",
       "UK           1.051944\n",
       "US           1.041599\n",
       "dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the coefficients exponential values\n",
    "np.exp(results2.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0150553002127556"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the inverse of the coefficient exponential of \n",
    "# ab_page (because the coefficient has a negative value)\n",
    "ad_page_exp_coef = 1/0.985168\n",
    "ad_page_exp_coef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From these coefficient exponential values, we can get the odds ratio for a level compared to the baseline, as follows:**<br>\n",
    "**1. For the ab_page, as compared to the baseline, we expect a multiplicative change in the odds of converting by 1.015, holding all other variables constant.**<br>\n",
    "**2. For the UK users, as compared to the baseline, we expect a multiplicative change in the odds of converting by 1.052, holding all other variables constant.**<br>\n",
    "**3. For the US users, as compared to the baseline, we expect a multiplicative change in the odds of converting by 1.042, holding all other variables constant.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h. Though you have now looked at the individual factors of country and page on conversion, we would now like to look at an interaction between page and country to see if there significant effects on conversion.  Create the necessary additional columns, and fit the new model.  \n",
    "\n",
    "Provide the summary results, and your conclusions based on the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "      <th>new_page</th>\n",
       "      <th>ab_page</th>\n",
       "      <th>intercept</th>\n",
       "      <th>country</th>\n",
       "      <th>UK</th>\n",
       "      <th>US</th>\n",
       "      <th>newpage_UK</th>\n",
       "      <th>newpage_US</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   timestamp      group landing_page  converted  \\\n",
       "0   851104  2017-01-21 22:11:48.556739    control     old_page          0   \n",
       "1   804228  2017-01-12 08:01:45.159739    control     old_page          0   \n",
       "2   661590  2017-01-11 16:55:06.154213  treatment     new_page          0   \n",
       "3   853541  2017-01-08 18:28:03.143765  treatment     new_page          0   \n",
       "4   864975  2017-01-21 01:52:26.210827    control     old_page          1   \n",
       "\n",
       "   new_page  ab_page  intercept country  UK  US  newpage_UK  newpage_US  \n",
       "0         0        0          1      US   0   1           0           0  \n",
       "1         0        0          1      US   0   1           0           0  \n",
       "2         1        1          1      US   0   1           0           1  \n",
       "3         1        1          1      US   0   1           0           1  \n",
       "4         0        0          1      US   0   1           0           0  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the new variables for interaction between page and country\n",
    "new_df['newpage_UK'] = new_df['UK'] * new_df['new_page']\n",
    "new_df['newpage_US'] = new_df['US'] * new_df['new_page']\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366109\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>       <td>No. Iterations:</td>    <td>6.0000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>     <td>converted</td>    <td>Pseudo R-squared:</td>    <td>0.000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2020-03-24 20:41</td>       <td>AIC:</td>        <td>212782.6602</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>       <td>290584</td>            <td>BIC:</td>        <td>212846.1381</td>\n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>              <td>5</td>         <td>Log-Likelihood:</td>  <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>         <td>290578</td>          <td>LL-Null:</td>      <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>         <td>1.0000</td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>       <th>Coef.</th>  <th>Std.Err.</th>     <th>z</th>     <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th>  <td>-2.0040</td>  <td>0.0364</td>  <td>-55.0077</td> <td>0.0000</td> <td>-2.0754</td> <td>-1.9326</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ab_page</th>    <td>-0.0674</td>  <td>0.0520</td>   <td>-1.2967</td> <td>0.1947</td> <td>-0.1694</td> <td>0.0345</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>UK</th>         <td>0.0118</td>   <td>0.0398</td>   <td>0.2957</td>  <td>0.7674</td> <td>-0.0663</td> <td>0.0899</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>US</th>         <td>0.0175</td>   <td>0.0377</td>   <td>0.4652</td>  <td>0.6418</td> <td>-0.0563</td> <td>0.0914</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>newpage_UK</th> <td>0.0783</td>   <td>0.0568</td>   <td>1.3783</td>  <td>0.1681</td> <td>-0.0330</td> <td>0.1896</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>newpage_US</th> <td>0.0469</td>   <td>0.0538</td>   <td>0.8718</td>  <td>0.3833</td> <td>-0.0585</td> <td>0.1523</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                          Results: Logit\n",
       "==================================================================\n",
       "Model:              Logit            No. Iterations:   6.0000     \n",
       "Dependent Variable: converted        Pseudo R-squared: 0.000      \n",
       "Date:               2020-03-24 20:41 AIC:              212782.6602\n",
       "No. Observations:   290584           BIC:              212846.1381\n",
       "Df Model:           5                Log-Likelihood:   -1.0639e+05\n",
       "Df Residuals:       290578           LL-Null:          -1.0639e+05\n",
       "Converged:          1.0000           Scale:            1.0000     \n",
       "-------------------------------------------------------------------\n",
       "               Coef.   Std.Err.     z      P>|z|    [0.025   0.975]\n",
       "-------------------------------------------------------------------\n",
       "intercept     -2.0040    0.0364  -55.0077  0.0000  -2.0754  -1.9326\n",
       "ab_page       -0.0674    0.0520   -1.2967  0.1947  -0.1694   0.0345\n",
       "UK             0.0118    0.0398    0.2957  0.7674  -0.0663   0.0899\n",
       "US             0.0175    0.0377    0.4652  0.6418  -0.0563   0.0914\n",
       "newpage_UK     0.0783    0.0568    1.3783  0.1681  -0.0330   0.1896\n",
       "newpage_US     0.0469    0.0538    0.8718  0.3833  -0.0585   0.1523\n",
       "==================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the logistic regression model\n",
    "logit_mod3 = sm.Logit(new_df['converted'], new_df[['intercept', 'ab_page', 'UK', 'US', 'newpage_UK', 'newpage_US']])\n",
    "\n",
    "# fit the model\n",
    "results3 = logit_mod3.fit()\n",
    "\n",
    "# get results summary\n",
    "# note: using the 'summary' function, there was an internal error: the module\n",
    "# 'scipy.stats' has no attribute 'chisqprob'\n",
    "results3.summary2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From this summary, we can interpret the following:**<br>\n",
    "**1. The P-values for all the variables (except the intercept) are not low values (greater than 0.05), which suggests that these variables are not statistically significant for the conversion rate.**<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intercept     0.134794\n",
       "ab_page       0.934776\n",
       "UK            1.011854\n",
       "US            1.017682\n",
       "newpage_UK    1.081428\n",
       "newpage_US    1.048001\n",
       "dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exponentiate each of the coefficients in results3\n",
    "np.exp(results3.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The exponentiated coefficients for these categorical variables can give us the odds ratio as follows:**<br>\n",
    "**1. For the new pages in UK (newpage_UK), as compared to the baseline, we expect a multiplicative change in the odds of converting (being 1) by 1.0814, holding all other variables constant.**<br>\n",
    "**2. For the new pages in US (newpage_US), as compared to the baseline, we expect a multiplicative change in the odds of converting (being 1) by 1.0480,holding all other variables constant.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='conclusions'></a>\n",
    "## Directions to Submit\n",
    "\n",
    "> Before you submit your project, you need to create a .html or .pdf version of this notebook in the workspace here. To do that, run the code cell below. If it worked correctly, you should get a return code of 0, and you should see the generated .html file in the workspace directory (click on the orange Jupyter icon in the upper left).\n",
    "\n",
    "> Alternatively, you can download this report as .html via the **File** > **Download as** submenu, and then manually upload it into the workspace directory by clicking on the orange Jupyter icon in the upper left, then using the Upload button.\n",
    "\n",
    "> Once you've done this, you can submit your project by clicking on the \"Submit Project\" button in the lower right here. This will create and submit a zip file with this .ipynb doc and the .html or .pdf version you created. Congratulations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from subprocess import call\n",
    "call(['python', '-m', 'nbconvert', 'Analyze_ab_test_results_notebook.ipynb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
